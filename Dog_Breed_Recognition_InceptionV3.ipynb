{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Platform: Windows-10-10.0.16299-SP0\n",
      "Tensorflow version: 1.5.0\n",
      "Keras version: 2.1.3\n"
     ]
    }
   ],
   "source": [
    "# 這個Jupyter Notebook的環境\n",
    "import platform\n",
    "import tensorflow\n",
    "import keras\n",
    "print(\"Platform: {}\".format(platform.platform()))\n",
    "print(\"Tensorflow version: {}\".format(tensorflow.__version__))\n",
    "print(\"Keras version: {}\".format(keras.__version__))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "該原始數據集包含25,000張狗和貓的圖像（每個類別12,500個），大小為543MB（壓縮）。下載和解壓縮後，我們將創建一個包含三個子集的新數據集：一組包含每個類的1000個樣本的訓練集，每組500個樣本的驗證集，最後一個包含每個類的500個樣本的測試集。\n",
    "\n",
    "資料準備\n",
    "從Kaggle點擊Download下載圖像資料檔training.zip。\n",
    "在這個Jupyter Notebook所在的目錄下產生一個新的子目錄\"data\"。\n",
    "把從kaggle下載的資料檔複製到\"data\"的目錄裡頭。\n",
    "將train.zip解壓縮\n",
    "最後你的目錄結構看起來像這樣:\n",
    "\n",
    "xx-yyy.ipynb\n",
    "data/\n",
    "└── train/\n",
    "    ├── cat.0.jpg\n",
    "    ├── cat.1.jpg\n",
    "    ├── ..\n",
    "    └── dog.12499.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\BB105Project\\dogrecognition\\Model\n",
      "Copy first 200 breed images to train_breed_dir complete!\n",
      "Copy next 50 brees images to validation_breed_dir complete!\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "# 專案的根目錄路徑\n",
    "os.chdir('D:\\\\BB105Project\\\\dogrecognition\\\\Model')\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "breed_dir =  os.listdir('data\\\\train')[:16]\n",
    "\n",
    "\n",
    "# 置放coco圖像資料與標註資料的目錄\n",
    "DATA_PATH = os.path.join(ROOT_DIR, \"data\")\n",
    "\n",
    "# 原始數據集的路徑 ./data/train\n",
    "original_dataset_dir = os.path.join(DATA_PATH, \"train\")\n",
    "\n",
    "# 存儲小數據集的目錄 ./data/cats_and_dogs_small\n",
    "base_dir = os.path.join(DATA_PATH, \"dog_breed\")\n",
    "if not os.path.exists(base_dir): \n",
    "    os.mkdir(base_dir)\n",
    "    \n",
    "#----------------------------------------------------------\n",
    "\n",
    "# 我們的訓練資料的目錄 ./data/cats_and_dogs_small/train\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "if not os.path.exists(train_dir): \n",
    "    os.mkdir(train_dir)\n",
    "\n",
    "# 我們的驗證資料的目錄 ./data/cats_and_dogs_small/validation\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "if not os.path.exists(validation_dir): \n",
    "    os.mkdir(validation_dir)\n",
    "\n",
    "# 我們的測試資料的目錄 ./data/cats_and_dogs_small/test\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "if not os.path.exists(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "    \n",
    "#----------------------------------------------------------  \n",
    "\n",
    "# 狗種的圖片的訓練資料目錄 ./data/cats_and_dogs_small/train/cats\n",
    "for breed in breed_dir:\n",
    "    train_cats_dir = os.path.join(train_dir, breed)\n",
    "    if not os.path.exists(train_cats_dir):\n",
    "        os.mkdir(train_cats_dir)\n",
    "\n",
    "    \n",
    "# 狗種的圖片的驗證資料目錄 ./data/cats_and_dogs_small/validation/cats\n",
    "for breed in breed_dir:\n",
    "    validation_cats_dir = os.path.join(validation_dir, breed)\n",
    "    if not os.path.exists(validation_cats_dir):\n",
    "        os.mkdir(validation_cats_dir)\n",
    "\n",
    "    \n",
    "# 狗種的圖片的測試資料目錄 ./data/cats_and_dogs_small/test/cats\n",
    "for breed in breed_dir:\n",
    "    test_cats_dir = os.path.join(test_dir, breed)\n",
    "    if not os.path.exists(test_cats_dir):\n",
    "        os.mkdir(test_cats_dir)\n",
    "    \n",
    "#----------------------------------------------------------\n",
    "\n",
    "# 複製前400個狗種的圖片到train_cats_dir\n",
    "for breed in breed_dir:\n",
    "    breed_path = os.path.join(original_dataset_dir,breed)\n",
    "    train_path = os.path.join(train_dir,breed)\n",
    "    fnames = os.listdir(breed_path)[:400]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(breed_path, fname)\n",
    "        dst = os.path.join(train_path, fname)\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "print('Copy first 200 breed images to train_breed_dir complete!')\n",
    "\n",
    "# 複製下100個狗種的圖片到validation_cats_dir\n",
    "for breed in breed_dir:\n",
    "    breed_path = os.path.join(original_dataset_dir,breed)\n",
    "    validation_path = os.path.join(validation_dir,breed)\n",
    "    fnames = os.listdir(breed_path)[400:500]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(breed_path, fname)\n",
    "        dst = os.path.join(validation_path, fname)\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "print('Copy next 50 brees images to validation_breed_dir complete!')\n",
    "\n",
    "# 複製下500個貓的圖片到test_cats_dir\n",
    "#fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "#for fname in fnames:\n",
    "#    src = os.path.join(original_dataset_dir, fname)\n",
    "#    dst = os.path.join(test_cats_dir, fname)\n",
    "#    if not os.path.exists(dst):\n",
    "#        shutil.copyfile(src, dst)\n",
    "\n",
    "#print('Copy next 500 cat images to test_cats_dir complete!')\n",
    "\n",
    "\n",
    "\n",
    "#print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "#print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "#print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "#print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
    "#print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
    "#print('total test dog images:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徵提取 (feature extraction)\n",
    "特徵提取包括了使用預訓練好的網絡模型來從新樣本中提取特徵。這些特徵通過一個\"新\"的分類器(從頭開始訓練)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "實例化一個VGG16模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "conv_base = InceptionV3(weights='imagenet',\n",
    "                        include_top=False, # 在這裡告訴 keras我們只需要卷積基底的權重模型資訊\n",
    "                        input_shape=(150,150,3)) # 宣告我們要處理的圖像大小與顏色通道數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們向構造函數傳遞了三個參數：\n",
    "\n",
    "weights, 指定從哪個權重檢查點從中初始化模型\n",
    "\n",
    "include_top, 這是指在網絡頂部要包括或不包含密集連接的分類器。默認情況下，這個密集連接的分類器將對應於ImageNet的1000個類別。因為我們打算用自己建構的分類器（只有兩個類別，貓和狗），因此我們不需要包括它。\n",
    "\n",
    "input_shape, 我們將餵進到網絡的圖像張量的形狀(shape)。這個參數純粹是可選的：如果我們設定，那麼網絡將能夠處理任何大小的輸入。\n",
    "以下是VGG16“卷積基底”架構的細節：它與您已經熟悉的簡單卷積網絡(convnets)非常相似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 74, 74, 32)   96          conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 74, 74, 32)   0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 72, 72, 32)   9216        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 72, 72, 32)   96          conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 72, 72, 32)   0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 72, 72, 64)   18432       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 72, 72, 64)   192         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 72, 72, 64)   0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 35, 35, 80)   240         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 35, 35, 80)   0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 33, 33, 192)  138240      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 33, 33, 192)  576         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 33, 33, 192)  0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 16, 16, 64)   192         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 16, 16, 64)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 16, 16, 96)   55296       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 16, 16, 48)   144         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 16, 16, 96)   288         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 16, 16, 48)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 16, 16, 96)   0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 16, 16, 64)   76800       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 16, 16, 96)   82944       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 16, 16, 64)   192         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 16, 16, 64)   192         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 16, 16, 96)   288         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 16, 16, 32)   96          conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 16, 16, 64)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 16, 16, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 16, 16, 96)   0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 16, 16, 32)   0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_100[0][0]             \n",
      "                                                                 activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 16, 16, 64)   192         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 16, 16, 64)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 16, 16, 96)   55296       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 16, 16, 48)   144         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 16, 16, 96)   288         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 16, 16, 48)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 16, 16, 96)   0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 16, 16, 64)   76800       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 16, 16, 96)   82944       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 16, 16, 64)   192         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 16, 16, 64)   192         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 16, 16, 96)   288         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 16, 16, 64)   192         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 16, 16, 64)   0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 16, 16, 64)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 16, 16, 96)   0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_107[0][0]             \n",
      "                                                                 activation_109[0][0]             \n",
      "                                                                 activation_112[0][0]             \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 16, 16, 64)   192         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, 16, 64)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 16, 16, 96)   55296       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 16, 16, 48)   144         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 16, 16, 96)   288         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 16, 16, 48)   0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 16, 16, 96)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 64)   76800       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 16, 16, 96)   82944       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 16, 16, 64)   192         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 16, 16, 64)   192         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 16, 16, 96)   288         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 16, 16, 64)   192         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 16, 16, 64)   0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 96)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 16, 16, 64)   0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_114[0][0]             \n",
      "                                                                 activation_116[0][0]             \n",
      "                                                                 activation_119[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 16, 16, 64)   192         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 64)   0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 16, 16, 96)   55296       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 16, 16, 96)   288         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 16, 16, 96)   0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 7, 7, 96)     82944       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 7, 7, 384)    1152        conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 7, 7, 96)     288         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 7, 7, 384)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 7, 7, 96)     0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_121[0][0]             \n",
      "                                                                 activation_124[0][0]             \n",
      "                                                                 max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 7, 7, 128)    384         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 7, 7, 128)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 7, 7, 128)    114688      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 7, 7, 128)    384         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 7, 7, 128)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 7, 7, 128)    114688      activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 7, 7, 128)    384         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 7, 7, 128)    384         conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 7, 7, 128)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 7, 7, 128)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 128)    114688      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 7, 7, 128)    114688      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 7, 7, 128)    384         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 7, 7, 128)    384         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 7, 7, 128)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 7, 7, 128)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 7, 7, 192)    172032      activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 7, 7, 192)    172032      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 7, 7, 192)    576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 7, 7, 192)    576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 7, 7, 192)    576         conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 7, 7, 192)    576         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 7, 7, 192)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 7, 7, 192)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 7, 7, 192)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 7, 7, 192)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_125[0][0]             \n",
      "                                                                 activation_128[0][0]             \n",
      "                                                                 activation_133[0][0]             \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 7, 7, 160)    480         conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 7, 7, 160)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 7, 7, 160)    179200      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 7, 7, 160)    480         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 7, 7, 160)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 7, 7, 160)    179200      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 7, 7, 160)    480         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 7, 7, 160)    480         conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 7, 7, 160)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 7, 7, 160)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 7, 7, 160)    179200      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 7, 7, 160)    179200      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 7, 7, 160)    480         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 7, 7, 160)    480         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 7, 7, 160)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 7, 7, 160)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 7, 7, 192)    215040      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 7, 7, 192)    215040      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 7, 7, 192)    576         conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 7, 7, 192)    576         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 7, 7, 192)    576         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 7, 7, 192)    576         conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 7, 7, 192)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 7, 7, 192)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 7, 7, 192)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 7, 7, 192)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_135[0][0]             \n",
      "                                                                 activation_138[0][0]             \n",
      "                                                                 activation_143[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 7, 7, 160)    480         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 7, 7, 160)    0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 7, 7, 160)    179200      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 7, 7, 160)    480         conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 7, 7, 160)    0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 7, 7, 160)    179200      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 7, 7, 160)    480         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 7, 7, 160)    480         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 7, 7, 160)    0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 7, 7, 160)    0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 7, 7, 160)    179200      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 7, 7, 160)    179200      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 7, 7, 160)    480         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 7, 7, 160)    480         conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 7, 7, 160)    0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 7, 7, 160)    0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 7, 7, 192)    215040      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 7, 7, 192)    215040      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 7, 7, 192)    576         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 7, 7, 192)    576         conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 7, 7, 192)    576         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 7, 7, 192)    576         conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 7, 7, 192)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 7, 7, 192)    0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 7, 7, 192)    0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 7, 7, 192)    0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_145[0][0]             \n",
      "                                                                 activation_148[0][0]             \n",
      "                                                                 activation_153[0][0]             \n",
      "                                                                 activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 7, 7, 192)    576         conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 7, 7, 192)    0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 7, 7, 192)    258048      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 7, 7, 192)    576         conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 7, 7, 192)    0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 7, 7, 192)    258048      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 7, 7, 192)    576         conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 7, 7, 192)    576         conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 7, 7, 192)    0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 7, 7, 192)    0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 7, 7, 192)    258048      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 7, 7, 192)    258048      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 7, 7, 192)    576         conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 7, 7, 192)    576         conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 7, 7, 192)    0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 7, 7, 192)    0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 7, 7, 192)    258048      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 7, 7, 192)    258048      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 7, 7, 192)    576         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 7, 7, 192)    576         conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 7, 7, 192)    576         conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 7, 7, 192)    576         conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 7, 7, 192)    0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 7, 7, 192)    0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 7, 7, 192)    0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 7, 7, 192)    0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_155[0][0]             \n",
      "                                                                 activation_158[0][0]             \n",
      "                                                                 activation_163[0][0]             \n",
      "                                                                 activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 7, 7, 192)    576         conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 7, 7, 192)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 7, 7, 192)    258048      activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 7, 7, 192)    576         conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 7, 7, 192)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 7, 7, 192)    258048      activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 7, 7, 192)    576         conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 7, 7, 192)    576         conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 7, 7, 192)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 7, 7, 192)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 3, 3, 320)    552960      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 3, 3, 192)    331776      activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 3, 3, 320)    960         conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 3, 3, 192)    576         conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 3, 3, 320)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 3, 3, 192)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_166[0][0]             \n",
      "                                                                 activation_170[0][0]             \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 3, 3, 448)    1344        conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 3, 3, 448)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 3, 3, 384)    1548288     activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 3, 3, 384)    1152        conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 3, 3, 384)    1152        conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 3, 3, 384)    0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 3, 3, 384)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 3, 3, 384)    442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 3, 3, 384)    442368      activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 3, 3, 384)    442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 3, 3, 384)    442368      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 3, 3, 384)    1152        conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 3, 3, 384)    1152        conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 3, 3, 384)    1152        conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 3, 3, 384)    1152        conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 3, 3, 320)    960         conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 3, 3, 384)    0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 3, 3, 384)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 3, 3, 384)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 3, 3, 384)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 3, 3, 192)    576         conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 3, 3, 320)    0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_173[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3, 3, 768)    0           activation_177[0][0]             \n",
      "                                                                 activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 3, 3, 192)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_171[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 3, 3, 448)    1344        conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 3, 3, 448)    0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 3, 3, 384)    1548288     activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 3, 3, 384)    1152        conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 3, 3, 384)    1152        conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 3, 3, 384)    0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 3, 3, 384)    0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 3, 3, 384)    442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_183 (Conv2D)             (None, 3, 3, 384)    442368      activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 3, 3, 384)    442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 3, 3, 384)    442368      activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 3, 3, 384)    1152        conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 3, 3, 384)    1152        conv2d_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 3, 3, 384)    1152        conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 3, 3, 384)    1152        conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 3, 3, 320)    960         conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 3, 3, 384)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 3, 3, 384)    0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 3, 3, 384)    0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 3, 3, 384)    0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 3, 3, 192)    576         conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 3, 3, 320)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_182[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 3, 768)    0           activation_186[0][0]             \n",
      "                                                                 activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 3, 3, 192)    0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_180[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 activation_188[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary() # 打印一下模型資訊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 方法2: (卷積基底:凍結 + 串接新的密集分類層) >> 重新訓練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在，我們來回顧一下我們提到的第二種特徵提取技術，這種方法要慢得多，而且會花更多的時間與計算資源，但是我們可以在訓練過程中利用數據擴充(data augmentation): 擴展conv_base模型，並進行端(end)對端(end)的訓練。\n",
    "\n",
    "請注意，這種手法真的是非常昂貴的，所以只有在你有GPU時才應該嘗試它：在CPU上是絕對棘手的。如果您無法在GPU上運行代碼，那麼前一個手法就是你要選的路。\n",
    "\n",
    "因為模型的行為就像堆積木，所以你可以添加一個模型（像我們的conv_base）到Sequential模型，就像添加一個圖層一樣。所以你可以執行以下操作："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 移花+接木"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential() # 產生一個新的網絡模型結構\n",
    "model.add(conv_base)        # 把預訓練的卷積基底疊上去\n",
    "model.add(layers.Flatten()) # 打平\n",
    "model.add(layers.Dense(256, activation='relu'))  # 疊上新的密集連接層來做為分類器\n",
    "model.add(layers.Dense(16, activation='softmax')) # 因為我的資料集只有兩類(cat & dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 3, 3, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               4718848   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                4112      \n",
      "=================================================================\n",
      "Total params: 26,525,744\n",
      "Trainable params: 26,491,312\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 192\n"
     ]
    }
   ],
   "source": [
    "# 看一下“凍結前”有多少可以被訓練的權重\n",
    "print('This is the number of trainable weights '\n",
    "      'before freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# “凍結”卷積基底\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights after freezing the conv base: 4\n"
     ]
    }
   ],
   "source": [
    "# 再看一下“凍結後”有多少可以被訓練的權重\n",
    "print('This is the number of trainable weights '\n",
    "      'after freezing the conv base:', len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 images belonging to 16 classes.\n",
      "Found 800 images belonging to 16 classes.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[18432,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: dense_3/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@dense_3/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_3/kernel, dense_3/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'dense_3/kernel/Assign', defined at:\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-087056636cba>\", line 7, in <module>\n    model.add(layers.Dense(256, activation='relu'))  # 疊上新的密集連接層來做為分類器\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\", line 492, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 590, in __call__\n    self.build(input_shapes[0])\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\core.py\", line 842, in build\n    constraint=self.kernel_constraint)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 414, in add_weight\n    constraint=constraint)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 392, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 366, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 62, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[18432,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: dense_3/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@dense_3/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_3/kernel, dense_3/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[18432,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: dense_3/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@dense_3/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_3/kernel, dense_3/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-db8c73e37600>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m       \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m       verbose = 2)\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1254\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1256\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2175\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2176\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2177\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2179\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1847\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1849\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2471\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2472\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2473\u001b[1;33m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m   2475\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m     \u001b[1;31m# hack for list_devices() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# list_devices() function is not available under tensorflow r1.3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[18432,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: dense_3/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@dense_3/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_3/kernel, dense_3/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'dense_3/kernel/Assign', defined at:\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-9-087056636cba>\", line 7, in <module>\n    model.add(layers.Dense(256, activation='relu'))  # 疊上新的密集連接層來做為分類器\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\", line 492, in add\n    output_tensor = layer(self.outputs[0])\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 590, in __call__\n    self.build(input_shapes[0])\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\core.py\", line 842, in build\n    constraint=self.kernel_constraint)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 414, in add_weight\n    constraint=constraint)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 392, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 229, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 366, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\", line 62, in assign\n    use_locking=use_locking, name=name)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Java\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[18432,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: dense_3/kernel/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@dense_3/kernel\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](dense_3/kernel, dense_3/random_uniform)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "import datetime as dt\n",
    "start = dt.datetime.now()\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# 請注意: 驗證用的資料不要進行資料的增強\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # 圖像資料的目錄\n",
    "        train_dir,\n",
    "        # 設定圖像的高(height)與寬(width)\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        # 因為我們的目標資料集只有兩類(cat & dog)\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='categorical')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc'])\n",
    "\n",
    "start = dt.datetime.now()\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)\n",
    "\n",
    "end = dt.datetime.now()\n",
    "print('Total time {} s.'.format((end - start).seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('breed16_InceptionV3.h5') # 把模型儲存到檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label='Training acc')\n",
    "plt.plot(epochs, val_acc, label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 微調 (fine-tuning)\n",
    "\n",
    "另一種廣泛使用的模型重覆利用技術，與_特徵提取(feature extraction)_相輔相成，是 _(微調) fine-tuning_。\n",
    "\n",
    "微調包括解凍用於特徵提取的凍結模型庫中的幾個頂層(top layers)，並且共同訓練新添加的模型部分（在我們的範例中是完全連接的分類器）和這些頂層。這被稱為“微調(fine-tuning)”，因為它稍微調整正在重複使用的模型中更抽象的表示，以使它們與當前的要處理的問題更相關。\n",
    "\n",
    "![fine-tuning VGG16](https://s3.amazonaws.com/book.keras.io/img/ch5/vgg16_fine_tuning.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True # 解凍 \"卷積基底\"\n",
    "\n",
    "# 所有層直到block4_pool都應該被凍結，而 block5_conv1，block5_conv2, block5_conv3 及 block5_pool則被解凍        \n",
    "layers_frozen = ['conv2d_182','conv2d_183','conv2d_186','conv2d_187','average_pooling2d_18','conv2d_180','batch_normalization_182','batch_normalization_183','batch_normalization_186','batch_normalization_187','conv2d_188','batch_normalization_180','activation_182','activation_183','activation_186','activation_187','batch_normalization_188','activation_180','mixed9_1','concatenate_4','activation_188','mixed10']\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name in layers_frozen:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "        \n",
    "# 把每一層是否可以被\"trainable\"的flat打印出來\n",
    "for layer in conv_base.layers:\n",
    "    print(\"{}: {}\".format(layer.name, layer.trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5), # 使用小的learn rate\n",
    "              metrics=['acc'])\n",
    "\n",
    "start = dt.datetime.now()\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=50,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)\n",
    "\n",
    "end = dt.datetime.now()\n",
    "print('Total time {} s.'.format((end - start).seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('breed16_InceptionV3_tunning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, label='Training acc')\n",
    "plt.plot(epochs, val_acc, label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def smooth_curve(points, factor=0.8):\n",
    "  smoothed_points = []\n",
    "  for point in points:\n",
    "    if smoothed_points:\n",
    "      previous = smoothed_points[-1]\n",
    "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "    else:\n",
    "      smoothed_points.append(point)\n",
    "  return smoothed_points\n",
    "\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(acc), label='Smoothed training acc')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_acc), label='Smoothed validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(loss), label='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "         smooth_curve(val_loss), label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
